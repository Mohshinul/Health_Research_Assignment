---
title: "Assignment4"
author: "Mohshinul Karim"
date: "2024-06-10"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
There are 3-4 packages you will need to install for today's practical: `install.packages(c("xgboost", "eegkit", "forecast", "tseries", "caret"))` apart from that everything else should already be available on your system. 

If you are using a newer Mac you may have to also install [quartz](https://www.xquartz.org/) to have everything work (do this if you see errors about `X11` during install/execution).

I will endeavour to use explicit imports to make it clear where functions are coming from (functions without `library_name::` are part of base R or a function we've defined in this notebook).

```{r libraries, echo=FALSE}
# Using the same library we used earlier in the course for tabular data because we know it works!
library(xgboost)

# EEG manipulation library in R (although very limited compared to signal processing libraries available in other languages, matlab might actually still be a leader in this specific area)
library(eegkit)

# some time series functions (that we only skim the depths of)
library(forecast)
library(tseries)
library(caret)

# just tidyverse libraries that should already be installed
library(dplyr)
library(reshape2)
library(purrr)
library(ggplot2)
```

## EEG Eye Detection Data

One of the most common types of medical sensor data (and one that we talked about during the lecture) are Electroencephalograms (EEGs).  
These measure mesoscale electrical signals (measured in microvolts) within the brain, which are indicative of a region of neuronal activity.
Typically, EEGs involve an array of sensors (aka channels) placed on the scalp with a high degree of covariance between sensors.

As EEG data can be very large and unwieldy, we are going to use a relatively small/simple dataset today from [this paper](http://ehrai.com/su/pdf/aihls2013.pdf).

This dataset is a 117 second continuous EEG measurement collected from a single person with a device called a "Emotiv EEG Neuroheadset".
In combination with the EEG data collection, a camera was used to record whether person being recorded had their eyes open or closed. 
This was eye status was then manually annotated onto the EEG data with `1` indicated the eyes being closed and `0` the eyes being open.
Measures microvoltages are listed in chronological order with the first measured value at the top of the dataframe.

Let's parse the data directly from the `h2o` library's (which we aren't actually using directly) test data S3 bucket:

```{r parse_data}
eeg_url <- "https://h2o-public-test-data.s3.amazonaws.com/smalldata/eeg/eeg_eyestate_splits.csv"
eeg_data <- read.csv(eeg_url)

# add timestamp
Fs <- 117 / nrow(eeg_data)
eeg_data <- transform(eeg_data, ds = seq(0, 116.99999, by = Fs), eyeDetection = as.factor(eyeDetection))
print(table(eeg_data$eyeDetection))

# split dataset into train, validate, test
eeg_train <- subset(eeg_data, split == 'train', select = -split)
print(table(eeg_train$eyeDetection))

eeg_validate <- subset(eeg_data, split == 'valid', select = -split)
eeg_test <- subset(eeg_data, split == 'test', select = -split)
```

**Q0: Knowing the `eeg_data` contains 117 seconds of data, inspect the `eeg_data` dataframe and the code above to and determine how many samples per second were taken?**

**Answer0:** 128.0342 (estimation is follows) [128 approximately]

```{r}
# Count the number of rows in the eeg_data dataframe
number_of_rows <- nrow(eeg_data)

# Print the number of rows
print(number_of_rows)
```

```{r}
Sample_per<-number_of_rows/117
print(Sample_per)
```


**1** How many EEG electrodes/sensors were used?

**Answer1:** 14 (estimation is follows)

```{r}
# Get the names of the columns
colnames(eeg_data)
```
```{r}
number_of_sensors <- length(colnames(eeg_data)) - 3
print(number_of_sensors)
```

### Exploratory Data Analysis

Now that we have the dataset and some basic parameters let's begin with the ever important/relevant exploratory data analysis.

First we should check there is no missing data!
```{r check_na}
sum(is.na(eeg_data))
```

Great, now we can start generating some plots to look at this data within the time-domain.

First we use `reshape2::melt()` to transform the `eeg_data` dataset from a wide format to a long format expected by `ggplot2`.

Specifically, this converts from "wide" where each electrode has its own column, to a "long" format, where each observation has its own row. 
This format is often more convenient for data analysis and visualization, especially when dealing with repeated measurements or time-series data.

We then use `ggplot2` to create a line plot of electrode intensities per sampling time, with the lines coloured by electrode, and the eye status annotated using dark grey blocks.

```{r plot_data}
melt <- reshape2::melt(eeg_data %>% dplyr::select(-split), id.vars=c("eyeDetection", "ds"), variable.name = "Electrode", value.name = "microvolts")


ggplot2::ggplot(melt, ggplot2::aes(x=ds, y=microvolts, color=Electrode)) + 
  ggplot2::geom_line() + 
  ggplot2::ylim(3500,5000) + 
  ggplot2::geom_vline(ggplot2::aes(xintercept=ds), data=dplyr::filter(melt, eyeDetection==1), alpha=0.005)
```

**Q2. Do you see any obvious patterns between eyes being open (dark grey blocks in the plot) and the EEG **

**Answer2:**  Overall, for most electrodes, the fluctuations seem similar. However, some electrodes exhibit sharp volatility at the moment of eye-opening, which return close to the regular path at the end of the eyes-open period or sharply decline. For the F4 and AF4 electrodes, this pattern is particularly noticeable.Most of the electrodes exibits either upward or downward trend during the eye open period. 


**Q3: Similarly, based on the distribution of eye open/close state over time to anticipate any temporal correlation between these states?**

**Answer3:** During eye open states, increased brain activity and variability are observed, particularly in electrodes like F8, AF4, and P7. During eye closed states (white areas), the EEG signals stabilize, indicating reduced brain activity for the 3 electrodes. The regular alternation between eye states suggests a rhythmic pattern, possibly related to a structured task or behavioral pattern during the recording. Overall, there is a noticeable shock during the transition periods from eyes closed to open and from open to closed.

Let's see if we can directly look at the distribution of EEG intensities and see how they related to eye status.


As there are a few extreme outliers in voltage we will use the `dplyr::filter` function to remove values outwith of 3750 to 50003. The function uses the `%in%` operator to check if each value of microvolts is within that range. The function also uses the `dplyr::mutate()` to change the type of the variable eyeDetection from numeric to a factor (R's categorical variable type).

```{r compare_distrib}
melt_train <- reshape2::melt(eeg_train, id.vars=c("eyeDetection", "ds"), variable.name = "Electrode", value.name = "microvolts")

# filter huge outliers in voltage
filt_melt_train <- dplyr::filter(melt_train, microvolts %in% (3750:5000)) %>% dplyr::mutate(eyeDetection=as.factor(eyeDetection))

ggplot2::ggplot(filt_melt_train, ggplot2::aes(y=Electrode, x=microvolts, fill=eyeDetection)) + ggplot2::geom_boxplot()
```

Plots are great but sometimes so it is also useful to directly look at the summary statistics and how they related to eye status.
We will do this by grouping the data based on eye status and electrode before calculating the statistics using the convenient `dplyr::summarise` function.

```{r compare_summary_stats}
filt_melt_train %>% dplyr::group_by(eyeDetection, Electrode) %>% 
    dplyr::summarise(mean = mean(microvolts), median=median(microvolts), sd=sd(microvolts)) %>% 
    dplyr::arrange(Electrode)
```

**4Q. Based on these analyses are any electrodes consistently more intense or varied when eyes are open?**

**Answer4:** 
**Intensity:** Electrodes F7, P7, and O1 are consistently more intense (Higher mean value) when the eyes are open compared to when they are closed, in which F7 and O1 have higher value for both mean and median. 
**Variability:** Electrodes AF3, F7, F3, T8, F4, and AF4  varied (higher standard deviation) more when the eyes are open compared to when they are closed.

This analysis shows that the F7 electrodes have both higher intensity and variability when the eyes are open.


#### Time-Related Trends

As it looks like there may be a temporal pattern in the data we should investigate how it changes over time.  

First we will do a statistical test for stationarity:

```{r convert_to_tseries}
apply(eeg_train, 2, tseries::adf.test)
```

**Q5. What is stationarity?**
**Answer5:** Stationarity refers to a time series whose statistical properties such as mean, variance, and autocorrelation are constant over time. 

**Q6. Why are we interested in stationarity? What do the results of these tests tell us? (ignoring the lack of multiple comparison correction...)**

**Answer6:**
We are interested in stationarity because for time series data it provides a foundation for consistent, reliable, and accurate analysis and forecasting. A stationary series simplifies the research modelling process, enhancing statistical test validity and leading to better and more stable forecasts.

**Insight of the results of the test:**The results of the Augmented Dickey-Fuller (ADF) tests is the stationarity test of each time series in your EEG data. All the electrodes AF3, F7, F3, FC5, T7, P7, O1, O2, P8, T8, FC6, F4, F8, and AF4 have p-values of 0.01, indicating that the null hypothesis of a unit root (non-stationarity) can be rejected and these time series are stationary. Which implies their statistical properties do not change over time. p-value of eyeDetection is also 0.01implies it is stationary as well. However ds is not stationary as the p-value is 0.4045 as ds represents time or a time index, which inherently has a trend over time.

Then we may want to visually explore patterns of autocorrelation (previous values predict future ones) and cross-correlation (correlation across channels over time) using `forecast::ggAcf` function.

The ACF plot displays the cross- and auto-correlation values for different lags (i.e., time delayed versions of each electrode's voltage timeseries) in the dataset. 
It helps identify any significant correlations between channels and observations at different time points. 
Positive autocorrelation indicates that the increase in voltage observed in a given time-interval leads to a proportionate increase in the lagged time interval as well.
Negative autocorrelation indicates the opposite!

```{r correlation}
forecast::ggAcf(eeg_train %>% dplyr::select(-ds))
```

**Q7. Do any fields show signs of strong autocorrelation (diagonal plots)? Do any pairs of fields show signs of cross-correlation? Provide examples.**

**Answer7:**
**1. Strong Autocorrelation:** Yes, many field signs show autocorrelations. For example F7, FC5, FC6 etc. 
**2. Strong Cross-Correlation:** Yes. For example pairs like FC5 and F3, FC5 and F7, O1 and O2 show strong cross-correlation


#### Frequency-Space 

We can also explore the data in frequency space by using a Fast Fourier Transform.  
After the FFT we can summarise the distributions of frequencies by their density across the power spectrum.
This will let us see if there any obvious patterns related to eye status in the overall frequency distributions.

```{r fft_open}
eegkit::eegpsd(eeg_train %>% dplyr::filter(eyeDetection == 0) %>% dplyr::select(-eyeDetection, -ds), Fs = Fs, xlab="Eye Open")
```

```{r fft_closed}
eegkit::eegpsd(eeg_train %>% dplyr::filter(eyeDetection == 1) %>% dplyr::select(-eyeDetection, -ds), Fs = Fs, xlab="Eye Closed")
```

**Q8. Do you see any differences between the power spectral densities for the two eye states? If so, describe them.**

**Answer8:** Yes I can see diferrences. Power Distribution: During closed, in specific frequency bands certain channels (e.g., 1, 7, 14) exhibit higher power concentrated .
During open eye, the power is more uniformly distributed across different frequencies and channels.
Frequency Range: Close eye shows more pronounced power in lower frequency ranges (as indicated by the concentrated bands) compared to open eye.
Channel-Specific Patterns: Channels 1, 7, and 14 are consistently showing higher power in both states. The nature of this power changes however, with eye state, being more concentrated when eyes are closed and more spread out when eyes are open.


#### Independent Component Analysis

We may also wish to explore whether there are multiple sources of neuronal activity being picked up by the sensors.  
This can be achieved using a process known as independent component analysis (ICA) which decorrelates the channels and identifies the primary sources of signal within the decorrelated matrix.

```{r ica, warning=FALSE}
ica <- eegkit::eegica(eeg_train %>% dplyr::select(-eyeDetection, -ds), nc=3, method='fast', type='time')
mix <- dplyr::as_tibble(ica$M)
mix$eyeDetection <- eeg_train$eyeDetection
mix$ds <- eeg_train$ds

mix_melt <- reshape2::melt(mix, id.vars=c("eyeDetection", "ds"), variable.name = "Independent Component", value.name = "M")


ggplot2::ggplot(mix_melt, ggplot2::aes(x=ds, y=M, color=`Independent Component`)) + 
  ggplot2::geom_line() + 
  ggplot2::geom_vline(ggplot2::aes(xintercept=ds), data=dplyr::filter(mix_melt, eyeDetection==1), alpha=0.005) +
  ggplot2::scale_y_log10()
```



**9** Does this suggest eye opening relates to an independent component of activity across the electrodes?

**Answer9:** The graph suggests that eye opening is related to the V1 independent component of activity across the electrodes. During periods when the eyes are open, the significant fluctuations and higher amplitude of V1 indicate that this component captures neural activity associated with visual and cognitive processes activated by eye opening. 


### Eye Opening Prediction

Now that we've explored the data let's use a simple model to see how well we can predict eye status from the EEGs:

```{r xgboost}
# Convert the training and validation datasets to matrices
eeg_train_matrix <- as.matrix(dplyr::select(eeg_train, -eyeDetection, -ds))
eeg_train_labels <- as.numeric(eeg_train$eyeDetection) -1

eeg_validate_matrix <- as.matrix(dplyr::select(eeg_validate, -eyeDetection, -ds))
eeg_validate_labels <- as.numeric(eeg_validate$eyeDetection) -1

# Build the xgboost model
model <- xgboost(data = eeg_train_matrix, 
                 label = eeg_train_labels,
                 nrounds = 100,
                 max_depth = 4,
                 eta = 0.1,
                 objective = "binary:logistic")

print(model)
```



**Q10 Using the `caret` library (or any other library/model type you want such as a naive Bayes) fit another model to predict eye opening.**

**Answer10:** Fit a Logistic Regression Model using caret:

```{r}
# Load necessary library
library(caret)

# Define the training control
train_control <- trainControl(method = "cv", number = 5)

# Train the Random Forest model
set.seed(123)
rf_model <- train(
  eyeDetection ~ ., 
  data = eeg_train, 
  method = "rf", 
  trControl = train_control,
  importance = TRUE
)

# Predict on the validation dataset
rf_pred <- predict(rf_model, eeg_validate)

# Print the Random Forest model
print(rf_model)


```

**Q11. Using the best performing of the two models (on the validation dataset) calculate and report the test performance (filling in the code below):**

```{r}
#Comparing the Performance of Both Models
# Load necessary library
library(caret)

# Convert XGBoost predictions to binary classes
xgb_pred_prob <- predict(model, eeg_validate_matrix)
xgb_pred_class <- ifelse(xgb_pred_prob > 0.5, 1, 0)

# Create a factor for the XGBoost predicted classes
xgb_pred_factor <- factor(xgb_pred_class, levels = c(0, 1))

# Create a factor for the true validation labels
eeg_validate_labels_factor <- factor(eeg_validate$eyeDetection, levels = c(0, 1))

# Calculate confusion matrix for XGBoost
xgb_confusion_matrix <- confusionMatrix(xgb_pred_factor, eeg_validate_labels_factor)

# Calculate confusion matrix for Random Forest
rf_confusion_matrix <- confusionMatrix(factor(rf_pred, levels = c(0, 1)), eeg_validate_labels_factor)

# Print the confusion matrices
print("XGBoost Confusion Matrix")
print(xgb_confusion_matrix)

print("Random Forest Confusion Matrix")
print(rf_confusion_matrix)

# Extract accuracies
xgb_accuracy <- xgb_confusion_matrix$overall["Accuracy"]
rf_accuracy <- rf_confusion_matrix$overall["Accuracy"]

# Check for any NA values in accuracy and handle them
xgb_accuracy <- ifelse(is.na(xgb_accuracy), 0, xgb_accuracy)
rf_accuracy <- ifelse(is.na(rf_accuracy), 0, rf_accuracy)

if (xgb_accuracy > rf_accuracy) {
  best_model <- "XGBoost"
  best_confusion_matrix <- xgb_confusion_matrix
} else {
  best_model <- "Random Forest"
  best_confusion_matrix <- rf_confusion_matrix
}

print(paste("The best performing model is:", best_model))
print(best_confusion_matrix)

```

**Answer11:** The Random Forest model outperforms the XGBoost model in several key aspects. 
**Random Forest Model:**
Accuracy: **0.9933**
95% CI: (0.9897, 0.9959)
Kappa: **0.9865**
Sensitivity: **0.9969**
Specificity: 0.9890
Pos Pred Value: **0.9909**
Neg Pred Value: **0.9963**
Balanced Accuracy: 0.9930
**XGBoost Model:**
Accuracy: 0.8318
95% CI: (0.8179, 0.845)
Kappa: 0.6586
Sensitivity: 0.8771
Specificity: 0.7774
Pos Pred Value: 0.8256
Neg Pred Value: 0.8403
Balanced Accuracy: 0.8272



**12** Describe 2 possible alternative modeling approaches for prediction of eye opening from EEGs we discussed in the lecture but haven't explored in this notebook.

**Answer12:** 1. Hidden Markov Models (HMMs): Hidden Markov Models represent systems where the observed data is believed to be generated by a sequence of hidden states where each state has a probability distribution over possible observations, and transitions between states which are governed by probabilities.
2. Gaussian Processes (GPs): They are non-parametric model used for regression and classification tasks. They gives a probabilistic approach. Using which we can model by defining a distribution over functions that fit the data. A GP is characterized by its mean function and covariance function (kernel).


**Q13. What are 2 R libraries you could use to implement these approaches? (note: you don't actually have to implement them though!)**
**Answer13:** 1. Hidden Markov Models (HMMs):depmixS4
              2. Gaussian Processes (GPs):kernlab

## Optional

**14** (Optional) As this is the last practical of the course - let me know how you would change future offerings of this course. This will not impact your marks!

- What worked and didn’t work for you (e.g., in terms of the practicals, tutorials, and lectures)?

- Was learning how to run the practicals on your own machines instead of a clean server that will disappear after the course worth the technical challenges?
 
- What would you add or remove from the course? 

- What was the main thing you will take away from this course?
